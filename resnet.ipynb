{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import resnet18 as r\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import Subset\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(batch_size = 32):\n",
    "\n",
    "    # Standard MNIST transform.\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    # Load MNIST train and test.\n",
    "    ds_train = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    ds_test = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    # Split train into train and validation.\n",
    "    val_size = 5000\n",
    "    I = np.random.permutation(len(ds_train))\n",
    "    ds_val = Subset(ds_train, I[:val_size])\n",
    "    ds_train = Subset(ds_train, I[val_size:])\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=True ,  num_workers=8)\n",
    "    test_dataloader = torch.utils.data.DataLoader(ds_test, batch_size=batch_size,  num_workers=8)\n",
    "    val_dataloader = torch.utils.data.DataLoader(ds_val, batch_size=batch_size,  num_workers=8)\n",
    "\n",
    "    return train_dataloader, test_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_ = r.ResNet18(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def model_pipeline():\n",
    "\n",
    "\n",
    "    #make the model, data and optimization problem\n",
    "    model, criterion, optimizer, trainloader, testloader, validationloader = create()\n",
    "\n",
    "    #train the model\n",
    "    train(model, trainloader, criterion, optimizer, validationloader)\n",
    "\n",
    "    #test the model\n",
    "    print(\"Accuracy test: \",test(model, testloader))\n",
    "        \n",
    "    #return model\n",
    "\n",
    "def create():\n",
    "    \n",
    "    #Create a model\n",
    "    model = resnet_.to(device)\n",
    "    nparameters = sum(p.numel() for p in model.parameters())\n",
    "    print(nparameters)\n",
    "    #Create the loss and optimizer\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    trainloader,testloader,validationloader = getData(batch_size=1024)\n",
    "\n",
    "    return model, criterion, optimizer,trainloader, testloader, validationloader\n",
    "\n",
    "# Function to train a model.\n",
    "def train(model, trainloader, criterion, optimizer, validationloader):\n",
    " \n",
    "\n",
    "    model.train()\n",
    "    losses, valacc = [], []  \n",
    "\n",
    "    for epoch in range(5):\n",
    "        \n",
    "        progress_bar = tqdm(trainloader, desc=f'Training epoch {epoch}', leave=False)\n",
    "        \n",
    "        for batch, (images, labels) in enumerate(progress_bar):\n",
    "        \n",
    "            loss = train_batch(images, labels,model, optimizer, criterion)\n",
    "            acc = test(model, validationloader)\n",
    "            progress_bar.update(1)\n",
    "            \n",
    "            logs = {\"loss\": loss.detach().item(), \"val_acc\": acc}\n",
    "            progress_bar.set_postfix(**logs)\n",
    "        \n",
    "            losses.append(loss.item())\n",
    "            valacc.append(acc)\n",
    "\n",
    "    return np.mean(losses)\n",
    "\n",
    "def train_batch(images, labels, model, optimizer, criterion):\n",
    "\n",
    "    #insert data into cuda if available\n",
    "    images,labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward pass\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    #backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    #step with optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            oututs = model(images)\n",
    "            _, predicated = torch.max(oututs.data, 1)\n",
    "            total += labels.size(0)\n",
    "\n",
    "            correct += (predicated == labels).sum().item()\n",
    "\n",
    "        return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nparameters = sum(p.numel() for p in resnet_.parameters())\n",
    "nparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de6e881c9795ea54ebc10ce65310b6ce74b497001d3a02ac9093b1b31ec41895"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
